{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2: classifying embeddings with Gemini API\n",
    "Use embeddings produced by the gemini API to train a classifier that can classify newsgroup posts into categories based on post content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install packages and set up API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # import only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{mag['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\",\"\",text)\n",
    "    # Truncate each entry to 5,000 characters\n",
    "    text = text[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2: classifying embeddings with Gemini API\n",
    "Use embeddings produced by the gemini API to train a classifier that can classify newsgroup posts into categories based on post content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install packages and set up API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## Remove sensitive information like names and emails. Keep only the subject and body\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # Extract only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncate each entry to 5,000 characters\n",
    "    text = text[:5000]\n",
    "\n",
    "    return text\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Put data points into dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
    "    )\n",
    "    # Clean up the text\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Match label to target name index\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample some of the data by taking 100 data points in the training dataset, and dropping a few of the categories to run through this tutorial. Choose the science categories to compare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Sample rows, selecting num_samples of each Label.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "\n",
    "    # We have fewer categories now, so re-calibrate the label encoding.\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "# Class name should contain 'sci' to keep science categories.\n",
    "# Try different labels from the data - see newsgroups_train.target_names\n",
    "CLASSES_TO_KEEP = \"sci\"\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "import tqdm\n",
    "from tqdm.rich import tqdm as tqdmr\n",
    "import warnings\n",
    "\n",
    "# Add tqdm to Pandas\n",
    "tqdmr.pandas()\n",
    "\n",
    "#...But suppress the experimental warning\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429,503})\n",
    "\n",
    "@retry.Retry(predicate=is_retriable, timeout=300.0)\n",
    "def embed_fn(text: str) -> list[float]:\n",
    "\n",
    "    # You will be performing classification, so set task_type accordingly. \n",
    "    response = client.models.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        contents=text,\n",
    "        config=types.EmbedContentConfig(\n",
    "            task_type=\"classification\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return response.embeddings[0].values\n",
    "\n",
    "def create_embeddings(df):\n",
    "    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fun)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_embeddings(df_train)\n",
    "df_test = create_embeddings(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input([input_size], name=\"embedding_inputs\"),\n",
    "            layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Derive the embedding size from observing the data. The embedding size can also be specified with the \"output_dimensionality\" parameter to \"embed_content\" if you need to reduce it.\n",
    "embedding_size = len(df_train[\"Embeddings\"].iloc[0])\n",
    "\n",
    "classifier = build_classification_model(\n",
    "    embedding_size, len(df_train['Class Name'].unique())\n",
    ")\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets\n",
    "y_train = df_train[\"Encoded Label\"]\n",
    "x_train = np.stack(df_train[\"Embeddings\"])\n",
    "y_val = df_test[\"Encoded Label\"]\n",
    "x_val = np.stack(df_test[\"Embeddings\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n",
    "\n",
    "# train the model\n",
    "history = classifier.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
